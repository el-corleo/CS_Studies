{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are charged with building a classifier with the highest possible accuracy for determining the category of phone plans from user behavior. Below are the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# if training and validation accuracy is more than 5% off, throw away\n",
    "TRAIN_VALID_DELTA_THRESHOLD = 0.05\n",
    "\n",
    "# array indices\n",
    "ACC_TRAIN = 0\n",
    "ACC_VALID = 1\n",
    "DEPTH = 2\n",
    "N_ESTIMATORS = 2\n",
    "SOLVER = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_data = pd.read_csv(\"/datasets/users_behavior.csv\")\n",
    "\n",
    "display(users_data.head())\n",
    "display(users_data.info())\n",
    "\n",
    "data_train_model, data_test = train_test_split(users_data, test_size=0.2, random_state=54321)\n",
    "data_train, data_valid = train_test_split(data_train_model, test_size=0.25, random_state=54321)\n",
    "\n",
    "# For hyperparameter tuning\n",
    "features_train = data_train.drop([\"is_ultra\"], axis=1)\n",
    "target_train = data_train[\"is_ultra\"]\n",
    "\n",
    "features_valid = data_valid.drop([\"is_ultra\"], axis=1)\n",
    "target_valid = data_valid[\"is_ultra\"]\n",
    "\n",
    "# For actual training\n",
    "features_train_model = data_train_model.drop([\"is_ultra\"], axis=1)\n",
    "target_train_model = data_train_model[\"is_ultra\"]\n",
    "\n",
    "features_test = data_test.drop([\"is_ultra\"], axis=1)\n",
    "target_test = data_test[\"is_ultra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "We split the data into training, validation, and testing sets at a 3:1:1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent category is Standard\n",
      "'Choose most frequent' accuracy = 0.6640746500777605\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "ultra_ratio = (pd.DataFrame(target_test).query(\"is_ultra == 1\").count() / len(target_test))[0]\n",
    "most_frequent = \"\"\n",
    "if ultra_ratio < 0.5:\n",
    "    most_frequent = \"Standard\"\n",
    "else:\n",
    "    most_frequent = \"Ultra\"\n",
    "\n",
    "print(\"Most frequent category is\", most_frequent)\n",
    "\n",
    "guesses_non_ultra = np.zeros_like(target_test)\n",
    "accuracy_constant = accuracy_score(guesses_non_ultra, target_test)\n",
    "print(\"'Choose most frequent' accuracy =\", accuracy_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "We determine which is the most frequently chosen category and then just select it as our guess. With this method, we can already achieve a 66.4% accuracy, far better than random chance.\n",
    "\n",
    "But we must exceed 75% to find the most successful model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth = 5\n",
      "Best acc_train = 0.8246887966804979\n",
      "Best acc_valid = 0.8180404354587869\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "best_tree = [0, 0, 0] # accuracy_train, accuracy_valid, depth\n",
    "for depth in range(1,10):\n",
    "    dtc = DecisionTreeClassifier(max_depth=depth, random_state=54321)\n",
    "    dtc.fit(features_train, target_train)\n",
    "    dtc_preds_train = dtc.predict(features_train)    \n",
    "    accuracy_train = accuracy_score(target_train, dtc_preds_train)\n",
    "    dtc_preds_valid = dtc.predict(features_valid)\n",
    "    accuracy_valid = accuracy_score(target_valid, dtc_preds_valid)\n",
    "    if abs(accuracy_valid - accuracy_train) < TRAIN_VALID_DELTA_THRESHOLD and accuracy_valid > best_tree[ACC_VALID]:\n",
    "        best_tree[ACC_TRAIN] = accuracy_train\n",
    "        best_tree[ACC_VALID] = accuracy_valid\n",
    "        best_tree[DEPTH] = depth\n",
    "        \n",
    "print(\"Best depth =\", best_tree[DEPTH])\n",
    "print(\"Best acc_train =\", best_tree[ACC_TRAIN])\n",
    "print(\"Best acc_valid =\", best_tree[ACC_VALID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "After a relatively thorough search, we find that in with a depth of 5 decisions, we can achieve a validation accuracy of 81.8%, and very quickly at that. Further, there's less the 1% difference between the training and validation accuracy.\n",
    "\n",
    "This already exceeds the 75% goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators = 6\n",
      "Best acc_train = 0.8760373443983402\n",
      "Best acc_valid = 0.8304821150855366\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "best_forest = [0, 0, 0] # accuracy_train, accuracy_valid, n_estimators\n",
    "for n_estimators in range(5, 51):\n",
    "    rfc = RandomForestClassifier(max_depth=10, n_estimators=n_estimators, random_state=54321)\n",
    "    rfc.fit(features_train, target_train)\n",
    "    accuracy_train = rfc.score(features_train, target_train)\n",
    "    accuracy_valid = rfc.score(features_valid, target_valid)\n",
    "    if abs(accuracy_valid - accuracy_train) < TRAIN_VALID_DELTA_THRESHOLD and accuracy_valid > best_forest[ACC_VALID]:\n",
    "        best_forest[ACC_TRAIN] = accuracy_train\n",
    "        best_forest[ACC_VALID] = accuracy_valid\n",
    "        best_forest[N_ESTIMATORS] = n_estimators\n",
    "        \n",
    "print(\"Best n_estimators =\", best_forest[N_ESTIMATORS])\n",
    "print(\"Best acc_train =\", best_forest[ACC_TRAIN])\n",
    "print(\"Best acc_valid =\", best_forest[ACC_VALID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "With random forests, we find that 6 estimators get us an even higher accuracy for validation at 83% and a difference of less the 5% with the testing accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solver = newton-cg\n",
      "Best acc_train = 0.7562240663900415\n",
      "Best acc_valid = 0.7776049766718507\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "solvers = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "best_log_reg = [0, 0, ''] # accuracy_train, accuracy_valid, solver\n",
    "for solver in solvers:\n",
    "    lr = LogisticRegression(random_state=54321, solver=solver)\n",
    "    lr.fit(features_train, target_train)\n",
    "    accuracy_train = lr.score(features_train, target_train)\n",
    "    accuracy_valid = lr.score(features_valid, target_valid)\n",
    "    if abs(accuracy_valid - accuracy_train) < TRAIN_VALID_DELTA_THRESHOLD and accuracy_valid > best_log_reg[ACC_VALID]:\n",
    "        best_log_reg[ACC_TRAIN] = accuracy_train\n",
    "        best_log_reg[ACC_VALID] = accuracy_valid\n",
    "        best_log_reg[SOLVER] = solver\n",
    "\n",
    "        \n",
    "print(\"Best solver =\", best_log_reg[SOLVER])\n",
    "print(\"Best acc_train =\", best_log_reg[ACC_TRAIN])\n",
    "print(\"Best acc_valid =\", best_log_reg[ACC_VALID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "The worst performer is the logistic regression using the newton-cg solver, which yields a tolerable 77.7%--and oddly, a higher validation accuracy than its training accuracy. It is above our desired accuracy, but still the lowest of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Best Tree =  0.7713841368584758\n",
      "Accuracy Best Forest =  0.7651632970451011\n",
      "Accuracy Best Logistic Regression =  0.7076205287713841\n"
     ]
    }
   ],
   "source": [
    "# Fit the best of each of the three models\n",
    "# DECISION TREE\n",
    "dtc = DecisionTreeClassifier(max_depth=5, random_state=54321)\n",
    "dtc.fit(features_train_model, target_train_model)\n",
    "dtc_preds = dtc.predict(features_test)\n",
    "accuracy_tree = accuracy_score(target_test, dtc_preds)\n",
    "\n",
    "print(\"Accuracy Best Tree = \", accuracy_tree)\n",
    "\n",
    "# RANDOM FOREST\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=6, random_state=54321)\n",
    "rfc.fit(features_train_model, target_train_model)\n",
    "accuracy_forest = rfc.score(features_test, target_test)\n",
    "\n",
    "print(\"Accuracy Best Forest = \", accuracy_forest)\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "lr = LogisticRegression(solver=\"newton-cg\", random_state=54321)\n",
    "lr.fit(features_train_model, target_train_model)\n",
    "accuracy_log_reg = lr.score(features_test, target_test)\n",
    "\n",
    "print(\"Accuracy Best Logistic Regression = \", accuracy_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression fails to live up to expectations by dropping to a mere 70.7% accuracy, thus becoming disqualified from the running altogether.\n",
    "\n",
    "On the test set, we find that the highest performer is the Decision Tree model with an accuracy of 77.1% at a depth of 5. However, it only slightly outperforms the Random Forest model (by ~0.6%).\n",
    "\n",
    "Still, our goal is to find the one with the highest accuracy, and the answer is clearly the Decision Tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
